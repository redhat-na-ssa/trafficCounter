{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6af97e-3d05-4ac1-a01d-b0a9dd346370",
   "metadata": {},
   "source": [
    "# LoS Detection Strategy \n",
    "\n",
    "To detect the level of service (LOS) of a highway from a video of traffic, you would typically follow a series of steps involving video processing, vehicle detection and tracking, and LOS classification. Here's an outline of the process:\n",
    "\n",
    "1. Video Preprocessing\n",
    "Frame Extraction: Extract frames from the video at regular intervals, say every 5 seconds.\n",
    "Stabilization (if necessary): If the video is shaky or moving, apply video stabilization techniques to make it more suitable for analysis.\n",
    "2. Vehicle Detection and Tracking\n",
    "Object Detection: Use a deep learning model like YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), or Faster R-CNN to detect vehicles in each frame.\n",
    "Object Tracking: Implement a tracking algorithm such as SORT (Simple Online and Realtime Tracking) or DeepSORT to track the detected vehicles over multiple frames.\n",
    "3. Traffic Flow Analysis\n",
    "Vehicle Count: Count the number of vehicles passing through a defined section of the highway in each 5-second interval.\n",
    "Speed Estimation: Estimate the speed of each tracked vehicle by measuring the distance covered between frames and knowing the frame rate and camera calibration.\n",
    "Density Estimation: Calculate the density of vehicles on the highway segment by counting the number of vehicles per unit length of the road.\n",
    "4. Level of Service (LOS) Classification\n",
    "Traffic Flow Parameters: The LOS is determined based on parameters like speed, density, and flow (vehicles per hour). Use these metrics to classify the LOS.\n",
    "- Free Flow (LOS A): Low vehicle density, high speed, and smooth traffic flow.\n",
    "- Stable Flow (LOS B, C, D): Increasing vehicle density with minor to moderate delays.\n",
    "- Unstable Flow (LOS E): High vehicle density with frequent stops and low speeds.\n",
    "- Forced or Breakdown Flow (LOS F): Traffic congestion with very low speeds and frequent stops.\n",
    "- Classification Model: You can use predefined thresholds for these parameters or train a machine learning model to classify the LOS based on historical data.\n",
    "5. Output Generation\n",
    "Time-Series Data: Generate a time series of LOS values every 5 seconds based on the analysis.\n",
    "Visualization: Create visualizations or reports showing how the LOS changes over time during the video.\n",
    "Tools and Libraries\n",
    "OpenCV: For video processing and vehicle detection/tracking.\n",
    "TensorFlow/PyTorch: For implementing deep learning models for object detection.\n",
    "Scikit-learn/Pandas: For data analysis and LOS classification.\n",
    "Custom Scripts: For calculating traffic flow parameters and LOS.\n",
    "Example Workflow:\n",
    "Extract Frames: Extract frames at 5-second intervals from the video.\n",
    "Detect and Track Vehicles: Detect vehicles in each frame and track their movement across frames.\n",
    "Calculate Traffic Metrics: Compute the speed, count, and density of vehicles.\n",
    "Classify LOS: Use the calculated metrics to determine the LOS for each 5-second interval.\n",
    "Generate Output: Produce a report or visual representation of LOS over time.\n",
    "This approach provides a continuous and dynamic assessment of the highway's level of service using video data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24700db7-9682-493c-9f6f-5a1015812048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "# !mkdir scratch\n",
    "# !cd scratch\n",
    "# !git clone https://github.com/kadirnar/sort-pip.git\n",
    "# !cd sort-pip\n",
    "# !pip install .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b87e32-881d-4b5d-a045-a0c8cc8d8e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "VIDEO_PATH = '../SourceVideo/gdot-camera01.mp4'\n",
    "# VIDEO_PATH = '../SourceVideo/traffic-simPan.mp4'\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Adjust based on your video\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06d862-cb9d-496c-be40-2893c922f610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')  # Replace 'yolov8n.pt' with the specific version you want to use\n",
    "\n",
    "# Constants\n",
    "# VIDEO_PATH = 'highway_traffic.mp4'\n",
    "# FRAME_INTERVAL = 5  # seconds\n",
    "# VIDEO_FPS = 30  # Adjust based on your video\n",
    "# FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_LOS(vehicle_count, vehicle_speeds):\n",
    "    avg_speed = np.mean(vehicle_speeds) if vehicle_speeds else 0\n",
    "    density = vehicle_count / 100  # Simplified assumption of road length\n",
    "    \n",
    "    if density < 10 and avg_speed > 60:\n",
    "        return 'A'\n",
    "    elif density < 20 and avg_speed > 50:\n",
    "        return 'B'\n",
    "    elif density < 30 and avg_speed > 40:\n",
    "        return 'C'\n",
    "    elif density < 40 and avg_speed > 30:\n",
    "        return 'D'\n",
    "    elif density < 50 and avg_speed > 20:\n",
    "        return 'E'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "los_over_time = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    los = calculate_LOS(vehicle_count, vehicle_speeds)\n",
    "    los_over_time.append(los)\n",
    "    \n",
    "    # Add LOS label to the frame\n",
    "    cv2.putText(frame, f'LOS: {los}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the frame in Jupyter Notebook\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Output LOS over time\n",
    "for time, los in enumerate(los_over_time):\n",
    "    print(f\"Time {time * FRAME_INTERVAL}s: LOS {los}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e4e8b-e811-4b4e-8eda-98e7cb73f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Replace 'yolov8n.pt' with the specific version you want to use\n",
    "\n",
    "# Constants\n",
    "# VIDEO_PATH = 'highway_traffic.mp4'\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 30  # Adjust based on your video\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_LOS(vehicle_count, vehicle_speeds):\n",
    "    avg_speed = np.mean(vehicle_speeds) if vehicle_speeds else 0\n",
    "    density = vehicle_count / 100  # Simplified assumption of road length\n",
    "    \n",
    "    if density < 10 and avg_speed > 60:\n",
    "        return 'A'\n",
    "    elif density < 20 and avg_speed > 50:\n",
    "        return 'B'\n",
    "    elif density < 30 and avg_speed > 40:\n",
    "        return 'C'\n",
    "    elif density < 40 and avg_speed > 30:\n",
    "        return 'D'\n",
    "    elif density < 50 and avg_speed > 20:\n",
    "        return 'E'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "los_over_time = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    los = calculate_LOS(vehicle_count, vehicle_speeds)\n",
    "    los_over_time.append(los)\n",
    "    \n",
    "    # Add LOS label to the frame\n",
    "    cv2.putText(frame, f'LOS: {los}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the frame in Jupyter Notebook\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Output LOS over time\n",
    "for time, los in enumerate(los_over_time):\n",
    "    print(f\"Time {time * FRAME_INTERVAL}s: LOS {los}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12ecf0-9aaa-43c1-87a2-174d468a9fc8",
   "metadata": {},
   "source": [
    "# Streaming version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f503d-d3b3-417a-bd54-34552a846df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')  # Replace 'yolov8n.pt' with the specific version you want to use\n",
    "\n",
    "# Constants\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Estimated FPS for the stream; adjust as necessary\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "\n",
    "# Initialize video capture for webcam (use 0 for the default webcam)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('http://cvstreamer-cvdemo.apps.ocp4.davenet.local/stream/gdot-cameraC01.m3u8')\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_LOS(vehicle_count, vehicle_speeds):\n",
    "    avg_speed = np.mean(vehicle_speeds) if vehicle_speeds else 0\n",
    "    density = vehicle_count / 100  # Simplified assumption of road length\n",
    "    \n",
    "    if density < 10 and avg_speed > 60:\n",
    "        return 'A'\n",
    "    elif density < 20 and avg_speed > 50:\n",
    "        return 'B'\n",
    "    elif density < 30 and avg_speed > 40:\n",
    "        return 'C'\n",
    "    elif density < 40 and avg_speed > 30:\n",
    "        return 'D'\n",
    "    elif density < 50 and avg_speed > 20:\n",
    "        return 'E'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "los_over_time = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    los = calculate_LOS(vehicle_count, vehicle_speeds)\n",
    "    los_over_time.append(los)\n",
    "    \n",
    "    # Add LOS label to the frame\n",
    "    cv2.putText(frame, f'LOS: {los}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the frame in Jupyter Notebook\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Output LOS over time\n",
    "for time, los in enumerate(los_over_time):\n",
    "    print(f\"Time {time * FRAME_INTERVAL}s: LOS {los}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a2fa1-7f7b-4bf2-a8e6-755fae63dd86",
   "metadata": {},
   "source": [
    "# Newer Version with redis storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6531c959-09f7-439b-a957-5c7209c3930b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis\n",
      "  Downloading redis-5.0.8-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: opencv-python in /opt/app-root/lib/python3.9/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /opt/app-root/lib/python3.9/site-packages (from redis) (4.0.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/app-root/lib/python3.9/site-packages (from opencv-python) (1.26.4)\n",
      "Downloading redis-5.0.8-py3-none-any.whl (255 kB)\n",
      "Installing collected packages: redis\n",
      "Successfully installed redis-5.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install redis opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20a273b3-4f16-4b3e-9e97-931346690b25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Error 111 connecting to localhost:6379. Connection refused.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/redis/connection.py:277\u001b[0m, in \u001b[0;36mAbstractConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout:\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/redis/retry.py:62\u001b[0m, in \u001b[0;36mRetry.call_with_retry\u001b[0;34m(self, do, fail)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supported_errors \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/redis/connection.py:278\u001b[0m, in \u001b[0;36mAbstractConnection.connect.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry\u001b[38;5;241m.\u001b[39mcall_with_retry(\n\u001b[0;32m--> 278\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mlambda\u001b[39;00m error: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisconnect(error)\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout:\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/redis/connection.py:639\u001b[0m, in \u001b[0;36mConnection._connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocket.getaddrinfo returned an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/redis/connection.py:627\u001b[0m, in \u001b[0;36mConnection._connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;66;03m# connect\u001b[39;00m\n\u001b[0;32m--> 627\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msocket_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# set the socket_timeout now that we're connected\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 102\u001b[0m\n\u001b[1;32m     95\u001b[0m frame_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m: frame_count,\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecond\u001b[39m\u001b[38;5;124m'\u001b[39m: frame_count \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m VIDEO_FPS,\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlos\u001b[39m\u001b[38;5;124m'\u001b[39m: los,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: cv2\u001b[38;5;241m.\u001b[39mimencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    101\u001b[0m }\n\u001b[0;32m--> 102\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Display the frame (optional)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/redis/commands/core.py:2333\u001b[0m, in \u001b[0;36mBasicKeyCommands.set\u001b[0;34m(self, name, value, ex, px, nx, xx, keepttl, get, exat, pxat)\u001b[0m\n\u001b[1;32m   2330\u001b[0m     pieces\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2331\u001b[0m     options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 2333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpieces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/redis/client.py:545\u001b[0m, in \u001b[0;36mRedis.execute_command\u001b[0;34m(self, *args, **options)\u001b[0m\n\u001b[1;32m    543\u001b[0m pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_pool\n\u001b[1;32m    544\u001b[0m command_name \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 545\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mretry\u001b[38;5;241m.\u001b[39mcall_with_retry(\n\u001b[1;32m    549\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_command_parse_response(\n\u001b[1;32m    550\u001b[0m             conn, command_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m    551\u001b[0m         ),\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m error: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disconnect_raise(conn, error),\n\u001b[1;32m    553\u001b[0m     )\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/redis/connection.py:1074\u001b[0m, in \u001b[0;36mConnectionPool.get_connection\u001b[0;34m(self, command_name, *keys, **options)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_use_connections\u001b[38;5;241m.\u001b[39madd(connection)\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;66;03m# ensure this connection is connected to Redis\u001b[39;00m\n\u001b[0;32m-> 1074\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;66;03m# connections that the pool provides should be ready to send\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;66;03m# a command. if not, the connection was either returned to the\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# pool before all data has been read or the socket has been\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# closed. either way, reconnect and verify everything is good.\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/redis/connection.py:283\u001b[0m, in \u001b[0;36mAbstractConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeout connecting to server\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_message(e))\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m sock\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mConnectionError\u001b[0m: Error 111 connecting to localhost:6379. Connection refused."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import redis\n",
    "import pickle\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Initialize Redis connection\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "# Constants\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Estimated FPS for the stream; adjust as necessary\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('http://cvstreamer-cvdemo.apps.ocp4.davenet.local/stream/gdot-cameraC01.m3u8')\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_LOS(vehicle_count, vehicle_speeds):\n",
    "    avg_speed = np.mean(vehicle_speeds) if vehicle_speeds else 0\n",
    "    density = vehicle_count / 100  # Simplified assumption of road length\n",
    "    \n",
    "    if density < 10 and avg_speed > 60:\n",
    "        return 'A'\n",
    "    elif density < 20 and avg_speed > 50:\n",
    "        return 'B'\n",
    "    elif density < 30 and avg_speed > 40:\n",
    "        return 'C'\n",
    "    elif density < 40 and avg_speed > 30:\n",
    "        return 'D'\n",
    "    elif density < 50 and avg_speed > 20:\n",
    "        return 'E'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "los_over_time = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    los = calculate_LOS(vehicle_count, vehicle_speeds)\n",
    "    los_over_time.append(los)\n",
    "    \n",
    "    # Add LOS label to the frame\n",
    "    cv2.putText(frame, f'LOS: {los}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Serialize and store the data in Redis\n",
    "    frame_key = f\"frame_{frame_count}\"\n",
    "    data = {\n",
    "        'frame': frame_count,\n",
    "        'second': frame_count // VIDEO_FPS,\n",
    "        'los': los,\n",
    "        'image': cv2.imencode('.jpg', frame)[1].tobytes()\n",
    "    }\n",
    "    r.set(frame_key, pickle.dumps(data))\n",
    "    \n",
    "    # Display the frame (optional)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Output LOS over time\n",
    "for time, los in enumerate(los_over_time):\n",
    "    print(f\"Time {time * FRAME_INTERVAL}s: LOS {los}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec2ba8-6f00-41ec-9c2f-6d29041648f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
