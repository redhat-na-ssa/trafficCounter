{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6af97e-3d05-4ac1-a01d-b0a9dd346370",
   "metadata": {},
   "source": [
    "# LoS Detection Strategy \n",
    "\n",
    "To detect the level of service (LOS) of a highway from a video of traffic, you would typically follow a series of steps involving video processing, vehicle detection and tracking, and LOS classification. Here's an outline of the process:\n",
    "\n",
    "1. Video Preprocessing\n",
    "Frame Extraction: Extract frames from the video at regular intervals, say every 5 seconds.\n",
    "Stabilization (if necessary): If the video is shaky or moving, apply video stabilization techniques to make it more suitable for analysis.\n",
    "2. Vehicle Detection and Tracking\n",
    "Object Detection: Use a deep learning model like YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), or Faster R-CNN to detect vehicles in each frame.\n",
    "Object Tracking: Implement a tracking algorithm such as SORT (Simple Online and Realtime Tracking) or DeepSORT to track the detected vehicles over multiple frames.\n",
    "3. Traffic Flow Analysis\n",
    "Vehicle Count: Count the number of vehicles passing through a defined section of the highway in each 5-second interval.\n",
    "Speed Estimation: Estimate the speed of each tracked vehicle by measuring the distance covered between frames and knowing the frame rate and camera calibration.\n",
    "Density Estimation: Calculate the density of vehicles on the highway segment by counting the number of vehicles per unit length of the road.\n",
    "4. Level of Service (LOS) Classification\n",
    "Traffic Flow Parameters: The LOS is determined based on parameters like speed, density, and flow (vehicles per hour). Use these metrics to classify the LOS.\n",
    "- Free Flow (LOS A): Low vehicle density, high speed, and smooth traffic flow.\n",
    "- Stable Flow (LOS B, C, D): Increasing vehicle density with minor to moderate delays.\n",
    "- Unstable Flow (LOS E): High vehicle density with frequent stops and low speeds.\n",
    "- Forced or Breakdown Flow (LOS F): Traffic congestion with very low speeds and frequent stops.\n",
    "- Classification Model: You can use predefined thresholds for these parameters or train a machine learning model to classify the LOS based on historical data.\n",
    "5. Output Generation\n",
    "Time-Series Data: Generate a time series of LOS values every 5 seconds based on the analysis.\n",
    "Visualization: Create visualizations or reports showing how the LOS changes over time during the video.\n",
    "Tools and Libraries\n",
    "OpenCV: For video processing and vehicle detection/tracking.\n",
    "TensorFlow/PyTorch: For implementing deep learning models for object detection.\n",
    "Scikit-learn/Pandas: For data analysis and LOS classification.\n",
    "Custom Scripts: For calculating traffic flow parameters and LOS.\n",
    "Example Workflow:\n",
    "Extract Frames: Extract frames at 5-second intervals from the video.\n",
    "Detect and Track Vehicles: Detect vehicles in each frame and track their movement across frames.\n",
    "Calculate Traffic Metrics: Compute the speed, count, and density of vehicles.\n",
    "Classify LOS: Use the calculated metrics to determine the LOS for each 5-second interval.\n",
    "Generate Output: Produce a report or visual representation of LOS over time.\n",
    "This approach provides a continuous and dynamic assessment of the highway's level of service using video data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24700db7-9682-493c-9f6f-5a1015812048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "# !mkdir scratch\n",
    "# !cd scratch\n",
    "# !git clone https://github.com/kadirnar/sort-pip.git\n",
    "# !cd sort-pip\n",
    "# !pip install .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b87e32-881d-4b5d-a045-a0c8cc8d8e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "VIDEO_PATH = '../SourceVideo/gdot-camera01.mp4'\n",
    "# VIDEO_PATH = '../SourceVideo/traffic-simPan.mp4'\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Adjust based on your video\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06d862-cb9d-496c-be40-2893c922f610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')  # Replace 'yolov8n.pt' with the specific version you want to use\n",
    "\n",
    "# Constants\n",
    "# VIDEO_PATH = 'highway_traffic.mp4'\n",
    "# FRAME_INTERVAL = 5  # seconds\n",
    "# VIDEO_FPS = 30  # Adjust based on your video\n",
    "# FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_LOS(vehicle_count, vehicle_speeds):\n",
    "    avg_speed = np.mean(vehicle_speeds) if vehicle_speeds else 0\n",
    "    density = vehicle_count / 100  # Simplified assumption of road length\n",
    "    \n",
    "    if density < 10 and avg_speed > 60:\n",
    "        return 'A'\n",
    "    elif density < 20 and avg_speed > 50:\n",
    "        return 'B'\n",
    "    elif density < 30 and avg_speed > 40:\n",
    "        return 'C'\n",
    "    elif density < 40 and avg_speed > 30:\n",
    "        return 'D'\n",
    "    elif density < 50 and avg_speed > 20:\n",
    "        return 'E'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "los_over_time = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    los = calculate_LOS(vehicle_count, vehicle_speeds)\n",
    "    los_over_time.append(los)\n",
    "    \n",
    "    # Add LOS label to the frame\n",
    "    cv2.putText(frame, f'LOS: {los}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the frame in Jupyter Notebook\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Output LOS over time\n",
    "for time, los in enumerate(los_over_time):\n",
    "    print(f\"Time {time * FRAME_INTERVAL}s: LOS {los}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e4e8b-e811-4b4e-8eda-98e7cb73f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Replace 'yolov8n.pt' with the specific version you want to use\n",
    "\n",
    "# Constants\n",
    "# VIDEO_PATH = 'highway_traffic.mp4'\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 30  # Adjust based on your video\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_LOS(vehicle_count, vehicle_speeds):\n",
    "    avg_speed = np.mean(vehicle_speeds) if vehicle_speeds else 0\n",
    "    density = vehicle_count / 100  # Simplified assumption of road length\n",
    "    \n",
    "    if density < 10 and avg_speed > 60:\n",
    "        return 'A'\n",
    "    elif density < 20 and avg_speed > 50:\n",
    "        return 'B'\n",
    "    elif density < 30 and avg_speed > 40:\n",
    "        return 'C'\n",
    "    elif density < 40 and avg_speed > 30:\n",
    "        return 'D'\n",
    "    elif density < 50 and avg_speed > 20:\n",
    "        return 'E'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "los_over_time = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    los = calculate_LOS(vehicle_count, vehicle_speeds)\n",
    "    los_over_time.append(los)\n",
    "    \n",
    "    # Add LOS label to the frame\n",
    "    cv2.putText(frame, f'LOS: {los}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the frame in Jupyter Notebook\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Output LOS over time\n",
    "for time, los in enumerate(los_over_time):\n",
    "    print(f\"Time {time * FRAME_INTERVAL}s: LOS {los}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12ecf0-9aaa-43c1-87a2-174d468a9fc8",
   "metadata": {},
   "source": [
    "# Streaming version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f503d-d3b3-417a-bd54-34552a846df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')  # Replace 'yolov8n.pt' with the specific version you want to use\n",
    "\n",
    "# Constants\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Estimated FPS for the stream; adjust as necessary\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "\n",
    "# Initialize video capture for webcam (use 0 for the default webcam)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('http://cvstreamer-cvdemo.apps.ocp4.davenet.local/stream/gdot-cameraC01.m3u8')\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_LOS(vehicle_count, vehicle_speeds):\n",
    "    avg_speed = np.mean(vehicle_speeds) if vehicle_speeds else 0\n",
    "    density = vehicle_count / 100  # Simplified assumption of road length\n",
    "    \n",
    "    if density < 10 and avg_speed > 60:\n",
    "        return 'A'\n",
    "    elif density < 20 and avg_speed > 50:\n",
    "        return 'B'\n",
    "    elif density < 30 and avg_speed > 40:\n",
    "        return 'C'\n",
    "    elif density < 40 and avg_speed > 30:\n",
    "        return 'D'\n",
    "    elif density < 50 and avg_speed > 20:\n",
    "        return 'E'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "los_over_time = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    los = calculate_LOS(vehicle_count, vehicle_speeds)\n",
    "    los_over_time.append(los)\n",
    "    \n",
    "    # Add LOS label to the frame\n",
    "    cv2.putText(frame, f'LOS: {los}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the frame in Jupyter Notebook\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Output LOS over time\n",
    "for time, los in enumerate(los_over_time):\n",
    "    print(f\"Time {time * FRAME_INTERVAL}s: LOS {los}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a2fa1-7f7b-4bf2-a8e6-755fae63dd86",
   "metadata": {},
   "source": [
    "# Newer Version with mqtt storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531c959-09f7-439b-a957-5c7209c3930b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install paho-mqtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a273b3-4f16-4b3e-9e97-931346690b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Initialize MQTT client\n",
    "mqtt_client = mqtt.Client()\n",
    "mqtt_client.connect('mqtt-broker.trafficcounter.svc.cluster.local', 1883, 60)  # Use your service name and port\n",
    "\n",
    "# Constants\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Estimated FPS for the stream; adjust as necessary\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "ROAD_LENGTH = 400  # Example road length in meters\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('http://cv-streamer-trafficcounter.apps.ocpbare.davenet.local/stream/gdot-cameraC01.m3u8')\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_density(vehicle_count, road_length=400, vehicle_types=None):\n",
    "    density = vehicle_count / road_length  # Use actual road length\n",
    "    \n",
    "    # Adjust density based on vehicle types (if provided)\n",
    "    if vehicle_types:\n",
    "        vehicle_type_weights = {'car': 1.0, 'truck': 2.0, 'bus': 2.5}  # Example weights\n",
    "        weighted_count = sum(vehicle_type_weights.get(v_type, 1.0) for v_type in vehicle_types)\n",
    "        density = weighted_count / road_length\n",
    "    \n",
    "    return density\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "density_over_time = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    density = calculate_density(vehicle_count, ROAD_LENGTH)\n",
    "    density_over_time.append(density)\n",
    "    \n",
    "    # Add Density label to the frame\n",
    "    cv2.putText(frame, f'Density: {density:.2f} vehicles/m', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Encode the frame as JPEG and then as a base64 string\n",
    "    _, buffer = cv2.imencode('.jpg', frame)\n",
    "    image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "    # Prepare data to publish to MQTT\n",
    "    data = {\n",
    "        'frame': frame_count,\n",
    "        'second': frame_count // VIDEO_FPS,\n",
    "        'density': density,\n",
    "        'image': image_base64\n",
    "    }\n",
    "    \n",
    "    # Publish to MQTT topic\n",
    "    mqtt_client.publish('traffic/density', json.dumps(data))\n",
    "    \n",
    "    # Display the frame (optional)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Output Density over time\n",
    "for time, density in enumerate(density_over_time):\n",
    "    print(f\"Time {time * FRAME_INTERVAL}s: Density {density:.2f} vehicles/m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f127a-ea33-4654-8e94-46ef14ad779f",
   "metadata": {},
   "source": [
    "# Plot the density over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65469461-6ebf-4773-8bb0-e9e9e9ce6ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Initialize MQTT client\n",
    "mqtt_client = mqtt.Client()\n",
    "mqtt_client.connect('mqtt-broker.trafficcounter.svc.cluster.local', 1883, 60)  # Use your service name and port\n",
    "\n",
    "# Constants\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Estimated FPS for the stream; adjust as necessary\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "ROAD_LENGTH = 400  # Example road length in meters\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('http://cv-streamer-trafficcounter.apps.ocpbare.davenet.local/stream/gdot-cameraC01.m3u8')\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_density(vehicle_count, road_length=400, vehicle_types=None):\n",
    "    density = vehicle_count / road_length  # Use actual road length\n",
    "    \n",
    "    # Adjust density based on vehicle types (if provided)\n",
    "    if vehicle_types:\n",
    "        vehicle_type_weights = {'car': 1.0, 'truck': 2.0, 'bus': 2.5}  # Example weights\n",
    "        weighted_count = sum(vehicle_type_weights.get(v_type, 1.0) for v_type in vehicle_types)\n",
    "        density = weighted_count / road_length\n",
    "    \n",
    "    return density\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "density_over_time = []\n",
    "\n",
    "# Set up the plot for density\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    density = calculate_density(vehicle_count, ROAD_LENGTH)\n",
    "    current_time = frame_count // VIDEO_FPS\n",
    "    density_over_time.append((current_time, density))  # Store time (in seconds) and density\n",
    "    \n",
    "    # Add Density label to the frame\n",
    "    cv2.putText(frame, f'Density: {density:.2f} vehicles/m', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Encode the frame as JPEG and then as a base64 string\n",
    "    _, buffer = cv2.imencode('.jpg', frame)\n",
    "    image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "    # Update the plot dynamically\n",
    "    ax.clear()\n",
    "    times, densities = zip(*density_over_time)  # Unpack the list of tuples into two lists\n",
    "    ax.plot(times, densities, marker='o')\n",
    "    ax.set_title('Vehicle Density Over Time')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Density (vehicles/m)')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # Save the plot to a bytes buffer and encode as base64\n",
    "    plot_buffer = BytesIO()\n",
    "    plt.savefig(plot_buffer, format='png')\n",
    "    plot_buffer.seek(0)\n",
    "    plot_base64 = base64.b64encode(plot_buffer.getvalue()).decode('utf-8')\n",
    "    plot_buffer.close()\n",
    "    \n",
    "    clear_output(wait=True)  # Clear the previous plot in the notebook\n",
    "    display(fig)  # Display the updated plot\n",
    "    \n",
    "    # Prepare data to publish to MQTT\n",
    "    data = {\n",
    "        'frame': frame_count,\n",
    "        'second': current_time,\n",
    "        'density': density,\n",
    "        'image': image_base64,\n",
    "        'plot': plot_base64\n",
    "    }\n",
    "    \n",
    "    # Publish to MQTT topic\n",
    "    mqtt_client.publish('traffic/density', json.dumps(data))\n",
    "    \n",
    "    # Display the frame (optional)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Keep the final plot displayed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee07640f-a5dd-470d-ac5e-a98c5ff4dd3a",
   "metadata": {},
   "source": [
    "# Write images to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e2627c-46d0-4749-95f7-2cba0018d9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Initialize MQTT client\n",
    "mqtt_client = mqtt.Client()\n",
    "mqtt_client.connect('mqtt-broker.trafficcounter.svc.cluster.local', 1883, 60)  # Use your service name and port\n",
    "\n",
    "# Constants\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Estimated FPS for the stream; adjust as necessary\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "ROAD_LENGTH = 400  # Example road length in meters\n",
    "SAVE_DIR = '/opt/app-root/src/trafficcounter/notebooks'  # Directory to save the images\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('http://cv-streamer-trafficcounter.apps.ocpbare.davenet.local/stream/gdot-cameraC01.m3u8')\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_density(vehicle_count, road_length=400, vehicle_types=None):\n",
    "    density = vehicle_count / road_length  # Use actual road length\n",
    "    \n",
    "    # Adjust density based on vehicle types (if provided)\n",
    "    if vehicle_types:\n",
    "        vehicle_type_weights = {'car': 1.0, 'truck': 2.0, 'bus': 2.5}  # Example weights\n",
    "        weighted_count = sum(vehicle_type_weights.get(v_type, 1.0) for v_type in vehicle_types)\n",
    "        density = weighted_count / road_length\n",
    "    \n",
    "    return density\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "density_over_time = []\n",
    "\n",
    "# Set up the plot for density\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    density = calculate_density(vehicle_count, ROAD_LENGTH)\n",
    "    current_time = frame_count // VIDEO_FPS\n",
    "    density_over_time.append((current_time, density))  # Store time (in seconds) and density\n",
    "    \n",
    "    # Add Density label to the frame\n",
    "    cv2.putText(frame, f'Density: {density:.2f} vehicles/m', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Encode the frame as JPEG and then as a base64 string\n",
    "    _, buffer = cv2.imencode('.jpg', frame)\n",
    "    image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "    # Update the plot dynamically\n",
    "    ax.clear()\n",
    "    times, densities = zip(*density_over_time)  # Unpack the list of tuples into two lists\n",
    "    ax.plot(times, densities, marker='o')\n",
    "    ax.set_title('Vehicle Density Over Time')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Density (vehicles/m)')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Also save the plot to a bytes buffer and encode as base64\n",
    "    plot_buffer = BytesIO()\n",
    "    fig.savefig(plot_buffer, format='png')\n",
    "    plot_buffer.seek(0)\n",
    "    plot_base64 = base64.b64encode(plot_buffer.getvalue()).decode('utf-8')\n",
    "    plot_buffer.close()\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "\n",
    "    # Prepare data to publish to MQTT\n",
    "    data = {\n",
    "        'frame': frame_count,\n",
    "        'second': current_time,\n",
    "        'density': density,\n",
    "        'image': image_base64,\n",
    "        'plot': plot_base64\n",
    "    }\n",
    "    \n",
    "    # Publish to MQTT topic\n",
    "    mqtt_client.publish('traffic/density', json.dumps(data))\n",
    "\n",
    "#     # Save the plot as an image file\n",
    "#     plot_filename = os.path.join(SAVE_DIR, f'density_plot_{current_time}.png')\n",
    "#     fig.savefig(plot_filename)  # Save plot image\n",
    "#     print(f\"Saved density plot to {plot_filename}\")\n",
    "\n",
    "#     # Save frame as image file\n",
    "#     frame_filename = os.path.join(SAVE_DIR, f'frame_{frame_count}.jpg')\n",
    "#     cv2.imwrite(frame_filename, frame)\n",
    "#     print(f\"Saved frame to {frame_filename}\")\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Keep the final plot displayed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f66ae5-bd05-4fe8-8cce-93f461188cab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63655a-4083-4746-8003-1f216233518b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24282879-8e43-4a69-aad8-724abec96439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "mqt_broker = 'mqtt-broker.trafficcounter.svc.cluster.local'\n",
    "streaming_server = 'http://cv-streamer-trafficcounter.apps.ocp4.davenet.local/stream/gdot-cameraC01.m3u8'\n",
    "# streaming_server = 'https://sfs-lr-37.dot.ga.gov:443/rtplive/GDOT-CCTV-0475/playlist.m3u8'\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Initialize MQTT client\n",
    "mqtt_client = mqtt.Client()\n",
    "mqtt_client.connect(mqt_broker, 1883, 60)  # Use your service name and port\n",
    "\n",
    "# Constants\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Estimated FPS for the stream; adjust as necessary\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "ROAD_LENGTH = 400  # Example road length in meters\n",
    "SAVE_DIR = '/opt/app-root/src/trafficcounter/notebooks'  # Directory to save the images\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(streaming_server)\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_density(vehicle_count, road_length=400, vehicle_types=None):\n",
    "    density = vehicle_count / road_length  # Use actual road length\n",
    "    \n",
    "    # Adjust density based on vehicle types (if provided)\n",
    "    if vehicle_types:\n",
    "        vehicle_type_weights = {'car': 1.0, 'truck': 2.0, 'bus': 2.5}  # Example weights\n",
    "        weighted_count = sum(vehicle_type_weights.get(v_type, 1.0) for v_type in vehicle_types)\n",
    "        density = weighted_count / road_length\n",
    "    \n",
    "    return density\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "density_over_time = []\n",
    "\n",
    "# Set up the plot for density\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [0]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    density = calculate_density(vehicle_count, ROAD_LENGTH)\n",
    "    current_time = frame_count // VIDEO_FPS\n",
    "    density_over_time.append((current_time, density))  # Store time (in seconds) and density\n",
    "    \n",
    "    # Add Density label to the frame\n",
    "    cv2.putText(frame, f'Density: {density:.2f} vehicles/m', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Encode the frame as JPEG and then as a base64 string\n",
    "    _, buffer = cv2.imencode('.jpg', frame)\n",
    "    image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "    # Update the plot dynamically\n",
    "    ax.clear()\n",
    "    times, densities = zip(*density_over_time)  # Unpack the list of tuples into two lists\n",
    "    ax.plot(times, densities, marker='o')\n",
    "    ax.set_title('Vehicle Density Over Time')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Density (vehicles/m)')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Also save the plot to a bytes buffer and encode as base64\n",
    "    plot_buffer = BytesIO()\n",
    "    fig.savefig(plot_buffer, format='png')\n",
    "    plot_buffer.seek(0)\n",
    "    plot_base64 = base64.b64encode(plot_buffer.getvalue()).decode('utf-8')\n",
    "    plot_buffer.close()\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "\n",
    "    # Prepare data to publish to MQTT\n",
    "    data = {\n",
    "        'frame': frame_count,\n",
    "        'second': current_time,\n",
    "        'density': density,\n",
    "        'image': image_base64,\n",
    "        'plot': plot_base64\n",
    "    }\n",
    "    \n",
    "    # Publish to MQTT topic\n",
    "    mqtt_client.publish('traffic/density', json.dumps(data))\n",
    "\n",
    "#     # Save the plot as an image file\n",
    "#     plot_filename = os.path.join(SAVE_DIR, f'density_plot_{current_time}.png')\n",
    "#     fig.savefig(plot_filename)  # Save plot image\n",
    "#     print(f\"Saved density plot to {plot_filename}\")\n",
    "\n",
    "#     # Save frame as image file\n",
    "#     frame_filename = os.path.join(SAVE_DIR, f'frame_{frame_count}.jpg')\n",
    "#     cv2.imwrite(frame_filename, frame)\n",
    "#     print(f\"Saved frame to {frame_filename}\")\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Keep the final plot displayed\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd41ad-d874-4a00-9b75-8f89ddbef555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
