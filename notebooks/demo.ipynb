{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00dc0a2b-ea74-4734-95cc-fda4e25e8e5d",
   "metadata": {},
   "source": [
    "# LoS Detection Strategy \n",
    "\n",
    "To detect the level of service (LOS) of a highway from a video of traffic, you would typically follow a series of steps involving video processing, vehicle detection and tracking, and LOS classification. Here's an outline of the process:\n",
    "\n",
    "1. Video Preprocessing\n",
    "Frame Extraction: Extract frames from the video at regular intervals, say every 5 seconds.\n",
    "Stabilization (if necessary): If the video is shaky or moving, apply video stabilization techniques to make it more suitable for analysis.\n",
    "2. Vehicle Detection and Tracking\n",
    "Object Detection: Use a deep learning model like YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), or Faster R-CNN to detect vehicles in each frame.\n",
    "Object Tracking: Implement a tracking algorithm such as SORT (Simple Online and Realtime Tracking) or DeepSORT to track the detected vehicles over multiple frames.\n",
    "3. Traffic Flow Analysis\n",
    "Vehicle Count: Count the number of vehicles passing through a defined section of the highway in each 5-second interval.\n",
    "Speed Estimation: Estimate the speed of each tracked vehicle by measuring the distance covered between frames and knowing the frame rate and camera calibration.\n",
    "Density Estimation: Calculate the density of vehicles on the highway segment by counting the number of vehicles per unit length of the road.\n",
    "4. Level of Service (LOS) Classification\n",
    "Traffic Flow Parameters: The LOS is determined based on parameters like speed, density, and flow (vehicles per hour). Use these metrics to classify the LOS.\n",
    "- Free Flow (LOS A): Low vehicle density, high speed, and smooth traffic flow.\n",
    "- Stable Flow (LOS B, C, D): Increasing vehicle density with minor to moderate delays.\n",
    "- Unstable Flow (LOS E): High vehicle density with frequent stops and low speeds.\n",
    "- Forced or Breakdown Flow (LOS F): Traffic congestion with very low speeds and frequent stops.\n",
    "- Classification Model: You can use predefined thresholds for these parameters or train a machine learning model to classify the LOS based on historical data.\n",
    "5. Output Generation\n",
    "Time-Series Data: Generate a time series of LOS values every 5 seconds based on the analysis.\n",
    "Visualization: Create visualizations or reports showing how the LOS changes over time during the video.\n",
    "Tools and Libraries\n",
    "OpenCV: For video processing and vehicle detection/tracking.\n",
    "TensorFlow/PyTorch: For implementing deep learning models for object detection.\n",
    "Scikit-learn/Pandas: For data analysis and LOS classification.\n",
    "Custom Scripts: For calculating traffic flow parameters and LOS.\n",
    "Example Workflow:\n",
    "Extract Frames: Extract frames at 5-second intervals from the video.\n",
    "Detect and Track Vehicles: Detect vehicles in each frame and track their movement across frames.\n",
    "Calculate Traffic Metrics: Compute the speed, count, and density of vehicles.\n",
    "Classify LOS: Use the calculated metrics to determine the LOS for each 5-second interval.\n",
    "Generate Output: Produce a report or visual representation of LOS over time.\n",
    "This approach provides a continuous and dynamic assessment of the highway's level of service using video data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4d0f74-1d22-41db-a043-4c89a63db4aa",
   "metadata": {},
   "source": [
    "# 1. Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a45e8d-e828-45a5-b4e2-53c81407ed95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcc024-a997-4bb4-8ea3-ccd0f03bfc63",
   "metadata": {},
   "source": [
    "# Setup constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5067dc5-a6a0-4a62-beca-0e67097e3bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "mqt_broker = 'mqtt-broker.trafficcounter.svc.cluster.local'\n",
    "streaming_server = 'https://sfs-lr-37.dot.ga.gov:443/rtplive/GDOT-CCTV-0475/playlist.m3u8'\n",
    "# streaming_server = 'http://cv-streamer-trafficcounter.apps.ocpbare.davenet.local/stream/gdot-cameraC01.m3u8'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d064f23d-6c2d-4cd6-b40f-c6c2fb5e243e",
   "metadata": {},
   "source": [
    "# 3. Run the analysis on the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ccffd-9c83-4f6a-93f3-d3da70e4d0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Initialize MQTT client\n",
    "mqtt_client = mqtt.Client()\n",
    "mqtt_client.connect(mqt_broker, 1883, 60)  # Use your service name and port\n",
    "\n",
    "# Constants\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Estimated FPS for the stream; adjust as necessary\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "ROAD_LENGTH = 400  # Example road length in meters\n",
    "SAVE_DIR = '/opt/app-root/src/trafficcounter/notebooks'  # Directory to save the images\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(streaming_server)\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_density(vehicle_count, road_length=400, vehicle_types=None):\n",
    "    density = vehicle_count / road_length  # Use actual road length\n",
    "    \n",
    "    # Adjust density based on vehicle types (if provided)\n",
    "    if vehicle_types:\n",
    "        vehicle_type_weights = {'car': 1.0, 'truck': 2.0, 'bus': 2.5}  # Example weights\n",
    "        weighted_count = sum(vehicle_type_weights.get(v_type, 1.0) for v_type in vehicle_types)\n",
    "        density = weighted_count / road_length\n",
    "    \n",
    "    return density\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "density_over_time = []\n",
    "\n",
    "# Set up the plot for density\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    density = calculate_density(vehicle_count, ROAD_LENGTH)\n",
    "    current_time = frame_count // VIDEO_FPS\n",
    "    density_over_time.append((current_time, density))  # Store time (in seconds) and density\n",
    "    \n",
    "    # Add Density label to the frame\n",
    "    cv2.putText(frame, f'Density: {density:.2f} vehicles/m', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Encode the frame as JPEG and then as a base64 string\n",
    "    _, buffer = cv2.imencode('.jpg', frame)\n",
    "    image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "    # Update the plot dynamically\n",
    "    ax.clear()\n",
    "    times, densities = zip(*density_over_time)  # Unpack the list of tuples into two lists\n",
    "    ax.plot(times, densities, marker='o')\n",
    "    ax.set_title('Vehicle Density Over Time')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Density (vehicles/m)')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Also save the plot to a bytes buffer and encode as base64\n",
    "    plot_buffer = BytesIO()\n",
    "    fig.savefig(plot_buffer, format='png')\n",
    "    plot_buffer.seek(0)\n",
    "    plot_base64 = base64.b64encode(plot_buffer.getvalue()).decode('utf-8')\n",
    "    plot_buffer.close()\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "\n",
    "    # Prepare data to publish to MQTT\n",
    "    data = {\n",
    "        'frame': frame_count,\n",
    "        'second': current_time,\n",
    "        'density': density,\n",
    "        'image': image_base64,\n",
    "        'plot': plot_base64\n",
    "    }\n",
    "    \n",
    "    # Publish to MQTT topic\n",
    "    mqtt_client.publish('traffic/density', json.dumps(data))\n",
    "\n",
    "#     # Save the plot as an image file\n",
    "#     plot_filename = os.path.join(SAVE_DIR, f'density_plot_{current_time}.png')\n",
    "#     fig.savefig(plot_filename)  # Save plot image\n",
    "#     print(f\"Saved density plot to {plot_filename}\")\n",
    "\n",
    "#     # Save frame as image file\n",
    "#     frame_filename = os.path.join(SAVE_DIR, f'frame_{frame_count}.jpg')\n",
    "#     cv2.imwrite(frame_filename, frame)\n",
    "#     print(f\"Saved frame to {frame_filename}\")\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Keep the final plot displayed\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0f6f1-ab48-4bd3-bd48-1755247eeaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
